{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from recommender_system import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(path) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Create graph representation of dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Relative path to csv file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, usecols=['uid1', 'uid2', 'target'])\n",
    "    df.columns = ['uid1', 'uid2', 'weight']\n",
    "    df['weight'] = 1 / df['weight']\n",
    "    g = nx.from_pandas_edgelist(df, source='uid1', target='uid2', edge_attr=['weight'], create_using=nx.DiGraph())\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'data/validate/train_df.csv')\n",
    "users = pd.read_csv(f'data/validate/train_index_map.csv', index_col=0, header=None)[1].values\n",
    "test_df = pd.read_csv(f'data/validate/test_df.csv')\n",
    "train_graph = build_graph(f'data/validate/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = 1\n",
    "train_df = train_df.drop(columns=['intensity', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['target'] = 1\n",
    "test_df = test_df.drop(columns=['intensity', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = train_df[['uid1', 'uid2']].stack().value_counts(normalize=True)\n",
    "train_neg = pd.DataFrame({'uid1': np.random.choice(a=p.index.values, size=300000, p=p.values), \n",
    "                          'uid2': np.random.choice(a=p.index.values, size=300000, p=p.values),\n",
    "                          'target': [0] * 300000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = test_df[['uid1', 'uid2']].stack().value_counts(normalize=True)\n",
    "test_neg = pd.DataFrame({'uid1': np.random.choice(a=p.index.values, size=100000, p=p.values), \n",
    "                         'uid2': np.random.choice(a=p.index.values, size=100000, p=p.values),\n",
    "                         'target': [0] * 100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_errors(f):\n",
    "    def _arg_wrapper(uid1, uid2, g):\n",
    "        try: \n",
    "            return f(uid1, uid2, g)\n",
    "        except (KeyError, nx.NetworkXError, ValueError, ZeroDivisionError, nx.NodeNotFound):\n",
    "            return np.nan\n",
    "    return _arg_wrapper\n",
    "\n",
    "@skip_errors\n",
    "def CommonNeighbors(u, v, g):\n",
    "    u_neighbors = set(g.neighbors(u))\n",
    "    v_neighbors = set(g.neighbors(v))\n",
    "    return len(u_neighbors.intersection(v_neighbors))\n",
    "\n",
    "@skip_errors\n",
    "def AdamicAdar(u, v, g):\n",
    "    u_neighbors = set(g.neighbors(u))\n",
    "    v_neighbors = set(g.neighbors(v))\n",
    "    aa = 0\n",
    "    for i in u_neighbors.intersection(v_neighbors):\n",
    "        aa += 1 / math.log(len(list(g.neighbors(i))))\n",
    "    return aa\n",
    "\n",
    "@skip_errors\n",
    "def ResourceAllocation(u, v, g):\n",
    "    u_neighbors = set(g.neighbors(u))\n",
    "    v_neighbors = set(g.neighbors(v))\n",
    "    ra = 0\n",
    "    for i in u_neighbors.intersection(v_neighbors):\n",
    "        ra += 1 / float(len(list(g.neighbors(i))))\n",
    "    return ra\n",
    "\n",
    "@skip_errors\n",
    "def JaccardCoefficent(u, v, g):\n",
    "    u_neighbors = set(g.neighbors(u))\n",
    "    v_neighbors = set(g.neighbors(v))\n",
    "    return len(u_neighbors.intersection(v_neighbors)) / float(len(u_neighbors.union(v_neighbors)))\n",
    "\n",
    "@skip_errors\n",
    "def PreferentialAttachment(u, v, g):\n",
    "    return len(list(g.neighbors(u))) * len(list(g.neighbors(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "    'common_neighbors': CommonNeighbors, \n",
    "    'adamic_adar': AdamicAdar,\n",
    "    'resourse_allocation': ResourceAllocation,\n",
    "    'jaccard_coef': JaccardCoefficent,\n",
    "    'pref_attachment': PreferentialAttachment,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_neg], axis=0).sample(frac=1)\n",
    "test_df = pd.concat([test_df, test_neg], axis=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = nx.from_pandas_edgelist(train_df, source='uid1', target='uid2', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_set:\n",
    "    test_df[feature] = test_df.apply(lambda x: feature_set[feature](x['uid1'], x['uid2'], train_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_set:\n",
    "    train_df[feature] = train_df.apply(lambda x: feature_set[feature](x['uid1'], x['uid2'], train_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=['uid1', 'uid2', 'target']), train_df['target']\n",
    "X_test, y_test = test_df.drop(columns=['uid1', 'uid2', 'target']), test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = lgb.Dataset(np.array(X_train), np.array(y_train))\n",
    "te = lgb.Dataset(np.array(X_test), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "    'random_state': 0,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.8,\n",
    "    'learning_rate': 0.01,\n",
    "    'metric':'auc',\n",
    "    'num_leaves': 31,\n",
    "    'num_threads': 8,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\tvalid_0's auc: 0.610555\n",
      "[200]\tvalid_0's auc: 0.607249\n",
      "[300]\tvalid_0's auc: 0.604816\n",
      "[400]\tvalid_0's auc: 0.599304\n",
      "[500]\tvalid_0's auc: 0.594563\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.618067\n"
     ]
    }
   ],
   "source": [
    "bst = lgb.train(param_lgb, tr, num_boost_round=5000, \n",
    "          valid_sets=te, early_stopping_rounds=int(5 / param_lgb['learning_rate']), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def predict(user):\n",
    "    user_friends = list(train_graph.neighbors(user)) \n",
    "    new_df = pd.DataFrame({'uid1': user, 'uid2': list(set(users) - set(user_friends) - {user})})\n",
    "    for feature in feature_set:\n",
    "        new_df[feature] = new_df.apply(lambda x: feature_set[feature](x['uid1'], x['uid2'], train_graph), axis=1)\n",
    "    pred = bst.predict(new_df.drop(columns=['uid1', 'uid2']))\n",
    "    return pd.Series(pred, index=new_df['uid2']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_second_level_neighbors(graph) -> dict:\n",
    "    neighbors_dict = {}\n",
    "    for node in tqdm_notebook(sorted(graph.nodes)):\n",
    "        bfs = nx.bfs_successors(graph, node)\n",
    "        neighbors = next(bfs)[1]\n",
    "        second_level = []\n",
    "        for i in neighbors:\n",
    "            try:\n",
    "                neigh = next(bfs)[1]\n",
    "                second_level += neigh\n",
    "            except StopIteration:\n",
    "                break\n",
    "        neighbors_dict[node] = second_level\n",
    "    return neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_level_neighbors(graph) -> dict:\n",
    "    neighbors_dict = {}\n",
    "    for node in tqdm_notebook(sorted(graph.nodes)):\n",
    "        neighbors = set(graph.neighbors(node))\n",
    "        second_level = []\n",
    "        for i in neighbors:\n",
    "            second_level += list(graph.neighbors(i))\n",
    "        second_level = Counter(second_level)\n",
    "        del second_level[node] \n",
    "        for word in list(second_level):\n",
    "            if word in neighbors:\n",
    "                del second_level[word] \n",
    "        neighbors_dict[node] = second_level\n",
    "    return neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0b49245d634171811b809ebdf9e91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38993), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users = get_second_level_neighbors(train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular = train_df[['uid1', 'uid2']].stack().value_counts()\n",
    "popular = list(popular.index)[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def predict(user):\n",
    "    if user in train_graph.nodes:\n",
    "        neighbors = np.array(users[user].most_common(50))\n",
    "        if len(neighbors) > 0:\n",
    "            neighbors = neighbors[:, 0]\n",
    "        new_df = pd.DataFrame({'uid1': user, \n",
    "                               'uid2': neighbors})\n",
    "        if not new_df.empty:\n",
    "            for feature in feature_set:\n",
    "                new_df[feature] = new_df.apply(lambda x: feature_set[feature](x['uid1'], x['uid2'], train_graph), axis=1)\n",
    "            pred = bst.predict(new_df.drop(columns=['uid1', 'uid2']))\n",
    "            pred = new_df['uid2'].iloc[pred.argsort()[-5:]].values[::-1]\n",
    "            if len(pred) == 5:\n",
    "                return pred\n",
    "            else:\n",
    "                for i in range(5 - len(pred)):\n",
    "                    pred = np.append(pred, popular[i])\n",
    "                return pred\n",
    "        else:\n",
    "            return popular\n",
    "    else:\n",
    "        return popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user):\n",
    "    if user in train_graph.nodes:\n",
    "        pred = np.array(users[user].most_common()[:5])\n",
    "        if len(pred) > 0:\n",
    "            pred = pred[:, 0]\n",
    "        if len(pred) == 5:\n",
    "            return pred\n",
    "        else:\n",
    "            for i in range(5 - len(pred)):\n",
    "                pred = np.append(pred, popular[i])\n",
    "            return pred\n",
    "    else:\n",
    "        return popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = BaseModel().build_graph(f'data/validate/test_df.csv')\n",
    "test_users = BaseModel().get_neighbors_dict(test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364180f96cc44f43b707b1988c6b6669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26956), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "for user in tqdm_notebook(list(test_users.keys())):\n",
    "    predictions.append(predict(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019787983943326235"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk([list(x) for x in list(test_users.values())], predictions, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
